{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SpamClassifier.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP5268pLTk/lAcGK0716wo/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Musu1/Udacity_DataScience/blob/master/SpamClassifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNWKonVqF_Y9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXS5GqpqHtRz",
        "colab_type": "code",
        "outputId": "d7bb491c-bb0e-4fc7-ac34-71752a41003f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "data=pd.read_table('10data',names=['label','messages'])\n",
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>messages</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  label                                           messages\n",
              "0   ham  Go until jurong point, crazy.. Available only ...\n",
              "1   ham                      Ok lar... Joking wif u oni...\n",
              "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3   ham  U dun say so early hor... U c already then say...\n",
              "4   ham  Nah I don't think he goes to usf, he lives aro..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYwojloEIPJ6",
        "colab_type": "text"
      },
      "source": [
        "# **PreProcessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvFAPrZyIRfw",
        "colab_type": "code",
        "outputId": "0e259919-90ac-4e33-bfb7-407aeb55c279",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "data.loc[:,'label']=data.label.map({'ham':0,'spam':1})\n",
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>messages</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                           messages\n",
              "0      0  Go until jurong point, crazy.. Available only ...\n",
              "1      0                      Ok lar... Joking wif u oni...\n",
              "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3      0  U dun say so early hor... U c already then say...\n",
              "4      0  Nah I don't think he goes to usf, he lives aro..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qyr3n5XIptBo",
        "colab_type": "text"
      },
      "source": [
        "# **Training and Testing sets**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OP_Gm__px5V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train,x_test,y_train,y_test=train_test_split(data['messages'],data['label'],random_state=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_8xVD_zoa9L",
        "colab_type": "text"
      },
      "source": [
        "# **Implementing Bag of words model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EThv2uQL7cjh",
        "colab_type": "text"
      },
      "source": [
        "This **Bag of words(BoW)** model throws away all the order information of text and focusses on occurrence of words in a text.\n",
        "\n",
        "And also We cannot work with text directly when using machine learning algorithms. So this model also converts the text to numbers.\n",
        "\n",
        "**For example**\n",
        "```\n",
        "text = [\"The quick brown fox jumped over the lazy dog.\"]\n",
        "#create the transform\n",
        "vectorizer = CountVectorizer()\n",
        "# tokenize and build vocab\n",
        "vectorizer.fit(text)\n",
        "# summarize\n",
        "print(vectorizer.vocabulary_)\n",
        "# encode document\n",
        "vector = vectorizer.transform(text)\n",
        "# summarize encoded vector\n",
        "print(vector.shape)\n",
        "print(type(vector))\n",
        "print(vector.toarray())\n",
        "```\n",
        "\n",
        "The output would be\n",
        "```\n",
        "#Index assigned to each word and also all the words transformed into lower case and punctuation is removed.\n",
        "{'dog': 1, 'fox': 2, 'over': 5, 'brown': 0, 'quick': 6, 'the': 7, 'lazy': 4, 'jumped': 3} \n",
        "#Size od a vector which has this eight words so 8\n",
        "(1, 8)\n",
        "<class 'scipy.sparse.csr.csr_matrix'>\n",
        "#Finally occurence of each word in the sentence organized according to the index assigned\n",
        "[[1 1 1 1 1 1 1 2]]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7_4OuHNogqt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectorizer=CountVectorizer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wl_uvTC9pmmc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_data=vectorizer.fit_transform(x_train)\n",
        "testing_data=vectorizer.transform(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7d_qWcTqYa4",
        "colab_type": "text"
      },
      "source": [
        "# **Naive Bayes Implementation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zG1goWzq-St6",
        "colab_type": "text"
      },
      "source": [
        "Here we have implemented **Multinomial Naive Bayes** for text classification.\n",
        "\n",
        "MultinomialNB implements the naive Bayes algorithm for multinomially distributed data, and is one of the two classic naive Bayes variants used in text classification (where the data are typically represented as **word vector counts**)\n",
        "\n",
        "For example\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "# Compute the probability of an individual not having diabetes, given that, that individual got a positive test result.\n",
        "# In other words, compute P(~D|Pos).\n",
        "\n",
        "# The formula is: P(~D|Pos) = (P(~D) * P(Pos|~D) / P(Pos)\n",
        "\n",
        "# Note that P(Pos/~D) can be computed as 1 - P(Neg/~D). \n",
        "# P(D)\n",
        "p_diabetes = 0.01\n",
        "\n",
        "# P(~D)\n",
        "p_no_diabetes = 0.99\n",
        "\n",
        "# Sensitivity or P(Pos|D)\n",
        "p_pos_diabetes = 0.9\n",
        "\n",
        "# Specificity or P(Neg/~D)\n",
        "p_neg_no_diabetes = 0.9\n",
        "p_pos = p_diabetes * p_pos_diabetes + p_no_diabetes * (1 - p_neg_no_diabetes)\n",
        "p_diabetes_pos = p_diabetes * p_pos_diabetes / p_pos\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWft_DsrqXnW",
        "colab_type": "code",
        "outputId": "ec50b87e-d800-4ae6-d428-81c75dcf406d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "naive_bayes=MultinomialNB()\n",
        "naive_bayes.fit(training_data,y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxkze5zbrm-n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred=naive_bayes.predict(testing_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6E7EgQmrzXM",
        "colab_type": "code",
        "outputId": "1e8dc8e6-a630-4f94-c93d-b1e2d64ff9da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "accuracy_score(y_test,y_pred)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9885139985642498"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    }
  ]
}